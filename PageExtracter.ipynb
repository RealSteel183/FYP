{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eefa2c4-18ed-437d-b80b-b3506552888c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f626944-eb10-4359-a6b3-5ddbf7c13073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578babce-315a-4af6-ae6c-3f057e90902d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finding prioritized entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002e3488-6ede-4cc9-a691-4f9985cc3f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_prioritized_entry(entries):\n",
    "    # Priority comments\n",
    "    priority_comments = [\n",
    "        \"AA; Typical\",\n",
    "        \"Average of tension and compression\",\n",
    "        \"Typical;\",\n",
    "        \"Typical\",\n",
    "        \"AA2024;\",\n",
    "        \"AA2024\",\n",
    "        \"AA;\"\n",
    "    ]\n",
    "    \n",
    "    # Check each entry for prioritized comments\n",
    "    for entry in entries:\n",
    "        if any(comment in entry[\"comment\"] for comment in priority_comments):\n",
    "            return entry  # Return the first matching prioritized entry\n",
    "    return entries[0] if entries else None  # Default to the first entry if no prioritized one found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643644c2-7ca1-48be-9852-d6017c58982c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad4adb5-1924-4098-964f-2b7d07a7c335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_density(soup):\n",
    "    row_patterns = [\n",
    "        r\"Density\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    density_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.?\\d*)\\s*(g/cc)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                density_data.append(entry)\n",
    "    \n",
    "    \n",
    "    return density_data[0] if density_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b02da7-688b-4e2f-a18c-feeb941a27e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Youngs Modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3efc7fc-9e24-46e9-a346-3fce9379ec7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_youngs_modulus(soup):\n",
    "    # Patterns to start capturing data\n",
    "    row_patterns = [\n",
    "        r\"Tensile\\s+Modulus\", \n",
    "        r\"Modulus\\s+of\\s+Elasticity\",\n",
    "        r\"Elastic\\s+Modulus\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    youngs_modulus_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.?\\d*)\\s*(\\w+)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                youngs_modulus_data.append(entry)\n",
    "    \n",
    "    best = find_prioritized_entry(youngs_modulus_data)\n",
    "    return best if youngs_modulus_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63527d-bd46-49b5-a500-c2a59488c5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Yield Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a54f1e4-23df-44d2-bf9f-ddf6734e3a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_yield_strength(soup):\n",
    "    row_patterns = [\n",
    "        r\"Tensile\\s+Strength,\\s*Yield\",\n",
    "        r\"Tensile\\s+Strength,\\s*Yield\\s*\",\n",
    "        r\"Tensile\\s+Strength\\s*Yield\",\n",
    "        r\"Yield\\s+Strength\", \n",
    "        r\"0\\.2%\\s*Proof\\s*Stress\",\n",
    "        r\"0\\.2%\\s*Yield\\s*Strength\",\n",
    "        r\"Proof\\s+Strength\",\n",
    "        r\"Lower\\s+Yield\\s+Strength\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    yield_strength_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.?\\d*)\\s*(\\w+)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                yield_strength_data.append(entry)\n",
    "    \n",
    "    best = find_prioritized_entry(yield_strength_data)\n",
    "    return best if yield_strength_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bd1a6-107e-441e-a2ea-de953fe4f8c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tensile Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3100969f-51e4-45f3-ab78-c3f7bf12cc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_tensile_strength(soup):\n",
    "    row_patterns = [\n",
    "        r\"Tensile\\s+Strength,\\s*Ultimate\",\n",
    "        r\"Ultimate\\s+Tensile\\s+Strength\",\n",
    "        r\"UTS\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    tensile_strength_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.?\\d*)\\s*(\\w+)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                tensile_strength_data.append(entry)\n",
    "    \n",
    "    best = find_prioritized_entry(tensile_strength_data)\n",
    "    return best if tensile_strength_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b67e6-3d0d-4656-a981-b2dcafa39d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fatigue Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d931d1-0b5e-445c-869e-33dc17126505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_fatigue_strength(soup):\n",
    "    # Patterns to start capturing data\n",
    "    row_patterns = [\n",
    "        r\"Fatigue\\s+Strength\",\n",
    "        r\"Endurance\\s+Limit\",\n",
    "        r\"Fatigue\\s+Limit\",\n",
    "        r\"Endurance\\s+Strength\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    fatigue_strength_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.?\\d*)\\s*(\\w+)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                fatigue_strength_data.append(entry)\n",
    "    \n",
    "    best = find_prioritized_entry(fatigue_strength_data)\n",
    "    return best if fatigue_strength_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398463ef-d6ae-42ab-be48-45233676952e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specific Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cefb7f9-ace8-402e-b0d2-97f8208e0f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_specific_heat(soup):\n",
    "    row_patterns = [\n",
    "        r\"Specific\\s+Heat\\s+Capacity\",\n",
    "        r\"Specific\\s+Heat\"\n",
    "    ]\n",
    "    \n",
    "    pattern_regex = re.compile('|'.join(row_patterns), re.IGNORECASE)\n",
    "\n",
    "    specific_heat_data = []\n",
    "    capturing = False  # Flag to control when to start and stop capturing data\n",
    "    last_valid_property_name = None  # To keep track of the last matched property name\n",
    "\n",
    "    # Iterate through all table rows in the document\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue\n",
    "        property_name = cells[0].get_text(strip=True) if len(cells) > 0 else \"\"\n",
    "        # Start or stop capturing based on the property name\n",
    "        if pattern_regex.search(property_name):\n",
    "            capturing = True\n",
    "            last_valid_property_name = property_name  # Update the last valid property name\n",
    "        elif property_name.strip() == \"\" and capturing:\n",
    "            # Continue capturing if property name is temporarily empty\n",
    "            property_name = last_valid_property_name\n",
    "        elif property_name.strip() != \"\" and not pattern_regex.search(property_name):\n",
    "            # Stop capturing if a new, non-empty, non-matching property name is encountered\n",
    "            capturing = False\n",
    "\n",
    "        # Capture data while the capturing flag is set\n",
    "        if capturing and len(cells) >= 3:\n",
    "            metric_value = cells[1].get_text(strip=True)\n",
    "            comment = cells[3].get_text(strip=True) if len(cells) > 3 else \"\"\n",
    "\n",
    "            # Extract numeric values and units\n",
    "            metric_match = re.search(r\"(\\d+\\.\\d*)\\s*(.+)\", metric_value)\n",
    "            if metric_match:\n",
    "                metric_value, metric_unit = metric_match.groups()\n",
    "\n",
    "                entry = {\n",
    "                    'metric_value': metric_value,\n",
    "                    'metric_unit': metric_unit,\n",
    "                    'comment': comment\n",
    "                }\n",
    "                specific_heat_data.append(entry)\n",
    "    \n",
    "    \n",
    "    return specific_heat_data[0] if specific_heat_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23451b-40d3-4458-b94b-d951a0da522f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CTE Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e81e79-21e7-4971-92b0-292a74d17d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cte_values(soup):\n",
    "    \n",
    "    header_patterns = [\n",
    "    r\"CTE\",\n",
    "    r\"CTE,\\s*linear\",\n",
    "    r\"Coefficient\\s+of\\s+Thermal\\s+Expansion\",\n",
    "    r\"Thermal\\s+Expansion\\s+Coefficent\",\n",
    "    r\"Linear\\s+Thermal\\s+Expansion\"\n",
    "    ]\n",
    "    \n",
    "    headers = soup.find_all('tr')\n",
    "    cte_data = []\n",
    "    prioritized_cte = None\n",
    "\n",
    "    # Regex to extract the CTE value and temperature range\n",
    "    cte_regex = re.compile(r\"(\\d+\\.?\\d*)\\s*µm/m-°C\\s*@Temperature\\s*(-?\\d+\\.?\\d*)\\s*-\\s*(-?\\d+\\.?\\d*)\\s*°C\")\n",
    "    \n",
    "    for header in headers:\n",
    "        if any(re.search(pattern, header.get_text(strip=True), re.IGNORECASE) for pattern in header_patterns):\n",
    "            parent_table = header.find_parent('table')\n",
    "            if parent_table:\n",
    "                rows = parent_table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cells = row.find_all('td')\n",
    "                    if cells:\n",
    "                        cell_text = ' '.join(cell.get_text(strip=True) for cell in cells)\n",
    "                        match = cte_regex.search(cell_text)\n",
    "                        if match:\n",
    "                            value, start_temp, end_temp = match.groups()\n",
    "                            cte_entry = {\n",
    "                                \"value\": value + \" µm/m-°C\",\n",
    "                                \"start_temp\": start_temp + \" °C\",\n",
    "                                \"end_temp\": end_temp + \" °C\"\n",
    "                            }\n",
    "                            cte_data.append(cte_entry)\n",
    "                            # Check if this entry matches the most desired temperature range\n",
    "                            if (start_temp == \"20.0\" or start_temp == \"20\")  and (end_temp == \"100.0\" or end_temp == \"100\"):\n",
    "                                prioritized_cte = cte_entry\n",
    "\n",
    "    # Select the best CTE value based on given conditions\n",
    "    if prioritized_cte:\n",
    "        return [prioritized_cte]  # Return the most prioritized CTE data\n",
    "    else:\n",
    "        # If no specific 20-100 range, look for any entry containing 20 as start or end\n",
    "        for cte in cte_data:\n",
    "            if cte[\"start_temp\"] == \"20.0 °C\" or cte[\"end_temp\"] == \"20.0 °C\":\n",
    "                return [cte]  # Return the first matching 20°C entry\n",
    "        # If none found, return the first available CTE value if there is any\n",
    "        return [cte_data[0]] if cte_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf5741-ca5c-4a84-b72d-9359686b8463",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Element Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abc1831-1a9b-4fa5-8352-58dd9ac1203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element_properties(soup): \n",
    "    # Find the <th> that contains \"Component Elements Properties\"\n",
    "    comp_elements_th = soup.find('th', string='Component Elements Properties')\n",
    "    \n",
    "    # Initialize a list to hold all the extracted rows' data\n",
    "    extracted_rows = []\n",
    "    \n",
    "    if comp_elements_th:\n",
    "        # Find the parent <table> of the identified <th> tag\n",
    "        parent_table = comp_elements_th.find_parent('table')\n",
    "        if parent_table:\n",
    "            # Get all the <tr> elements in the table\n",
    "            all_trs = parent_table.find_all('tr')\n",
    "            # Find the index of the <tr> that contains the <th> of interest\n",
    "            start_index = None\n",
    "            for index, tr in enumerate(all_trs):\n",
    "                if comp_elements_th in tr:\n",
    "                    start_index = index + 1\n",
    "                    break\n",
    "            # Extract all <tr> elements after the identified <th>\n",
    "            if start_index is not None:\n",
    "                for tr in all_trs[start_index:]:\n",
    "                    row_data = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "                    extracted_rows.append(row_data)\n",
    "\n",
    "    return extracted_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff488cb2-d4a1-48b0-8d6e-5f5dca67cd03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec16193b-5329-4242-ae80-a6e3ba3fd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse a single HTML file and extract required properties\n",
    "def parse_html(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "    # Initialize extracted properties with default values\n",
    "    extracted_properties = {\n",
    "        \"Alloy Name\": soup.title.text.strip(),  # Extract alloy name from the title tag\n",
    "        \"Density\": extract_density(soup),\n",
    "        \"Young's Modulus\": extract_youngs_modulus(soup),\n",
    "        \"Yield Strength\": extract_yield_strength(soup),\n",
    "        \"Tensile Strength\": extract_tensile_strength(soup),\n",
    "        \"Fatigue Strength\": extract_fatigue_strength(soup),\n",
    "        \"Specific Heat\": extract_specific_heat(soup),\n",
    "        \"Coefficient of Thermal Expansion\": extract_cte_values(soup),\n",
    "        \"Metal Chemical Notations\": extract_element_properties(soup)\n",
    "    }\n",
    "\n",
    "    return extracted_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8b026-b4cb-4128-8839-1d5283bc3020",
   "metadata": {},
   "source": [
    "### Al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e618f50-8535-4335-944b-c2bd6fd625a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code to process HTML files in a directory and write to CSV\n",
    "directory_path = './data/pagesAl'\n",
    "html_files = [f for f in os.listdir(directory_path) if f.endswith('.html')]\n",
    "#html_files=['page62.html']\n",
    "\n",
    "csv_file_path = 'extracted_Al_properties.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Alloy Name\", \"Density\", \"Young's Modulus\", \"Yield Strength\", \"Tensile Strength\", \"Fatigue Strength\", \"Specific Heat\", \"Coefficient of Thermal Expansion\", \"Metal Chemical Notations\"])\n",
    "    writer.writeheader()\n",
    "    for html_file in html_files:\n",
    "        file_path = os.path.join(directory_path, html_file)\n",
    "        properties = parse_html(file_path)\n",
    "        writer.writerow(properties)\n",
    "\n",
    "print(f\"Data extracted and written to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f64740-ab91-49dd-9cc2-ecfe477cf493",
   "metadata": {},
   "source": [
    "### Ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1da29f6-3d52-41d8-90ee-c1944536d399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and written to extracted_Ni_properties.csv.\n"
     ]
    }
   ],
   "source": [
    "# Your existing code to process HTML files in a directory and write to CSV\n",
    "directory_path = './data/pagesNi'\n",
    "html_files = [f for f in os.listdir(directory_path) if f.endswith('.html')]\n",
    "#html_files=['page62.html']\n",
    "\n",
    "csv_file_path = 'extracted_Ni_properties.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Alloy Name\", \"Density\", \"Young's Modulus\", \"Yield Strength\", \"Tensile Strength\", \"Fatigue Strength\", \"Specific Heat\", \"Coefficient of Thermal Expansion\", \"Metal Chemical Notations\"])\n",
    "    writer.writeheader()\n",
    "    for html_file in html_files:\n",
    "        file_path = os.path.join(directory_path, html_file)\n",
    "        properties = parse_html(file_path)\n",
    "        writer.writerow(properties)\n",
    "\n",
    "print(f\"Data extracted and written to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18decaa6-be96-4cf1-82a6-7bcd434085ef",
   "metadata": {},
   "source": [
    "### Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35529b4-81d3-48fd-abdc-66b7184e8520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and written to extracted_Ti_properties.csv.\n"
     ]
    }
   ],
   "source": [
    "# Your existing code to process HTML files in a directory and write to CSV\n",
    "directory_path = './data/pagesTi'\n",
    "html_files = [f for f in os.listdir(directory_path) if f.endswith('.html')]\n",
    "#html_files=['page62.html']\n",
    "\n",
    "csv_file_path = 'extracted_Ti_properties.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Alloy Name\", \"Density\", \"Young's Modulus\", \"Yield Strength\", \"Tensile Strength\", \"Fatigue Strength\", \"Specific Heat\", \"Coefficient of Thermal Expansion\", \"Metal Chemical Notations\"])\n",
    "    writer.writeheader()\n",
    "    for html_file in html_files:\n",
    "        file_path = os.path.join(directory_path, html_file)\n",
    "        properties = parse_html(file_path)\n",
    "        writer.writerow(properties)\n",
    "\n",
    "print(f\"Data extracted and written to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e0d5c-cd7c-45fd-a82e-e50a05bed926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
